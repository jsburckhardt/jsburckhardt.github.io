---
layout: post
title: Architecture notes - part 1
date: 2025-02-10
---

| **Topic**                         | **Description**                                                                                          | **Key Concepts & Strategies**                                                                                                                                                              | **Recommended Resources / Links**                                                                                                                                                                                                                                  |
|-----------------------------------|----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Distributed Systems Fundamentals  | Core principles behind designing systems that work across multiple nodes in a scalable and resilient way. | • Load balancing & scalability<br>• Data partitioning (sharding)<br>• Fault tolerance & recovery<br>• CAP theorem & consistency models                                     | • [Distributed Systems for Fun and Profit](http://book.mixu.net/distsys/)<br>• [CAP Twelve Years Later](http://www.infoq.com/presentations/cap-twelve-years-later/)                                                                                         |
| Caching Strategies                | Techniques to improve performance by temporarily storing data closer to the application/user.           | • In‑memory vs. distributed caching<br>• Cache invalidation & expiration policies<br>• Balancing consistency vs. performance                                                         | • [An Introduction to Caching – DigitalOcean](https://www.digitalocean.com/community/tutorials/an-introduction-to-caching)<br>• [Redis Introduction](https://redis.io/topics/introduction)                                                                     |
| Architectural Patterns            | High‑level approaches to system organization for scalability, maintainability, and resilience.          | • Microservices vs. monolithic architectures<br>• Event‑driven architecture<br>• Service-oriented patterns<br>• When to centralize cross‑cutting concerns vs. decentralize them | • [Microservices vs Monolith: Which Architecture is Right for You](https://medium.com/@sikachu/microservices-vs-monolith-which-architecture-is-right-for-you-44704e92f258)<br>• [Event‑Driven Architecture: A Key to Modern Software](https://dzone.com/articles/event-driven-architecture-a-key-to-modern-software) |
| Rate Limiter Pattern              | Patterns for controlling the rate of incoming requests to prevent system overload.                     | • Fixed window, sliding window, and token bucket algorithms<br>• Trade‑offs between simple implementation and smooth request distribution                                          | • [How to Build a Rate Limiter](https://dev.to/jameshamann/how-to-build-a-rate-limiter-1nhm)<br>• [Implementing a Rate Limiter in Node.js](https://medium.com/@etiennedub/implementing-a-rate-limiter-in-node-js-86f09e5b42a0)                                     |
| API Gateway & Service Mesh Patterns| Patterns for managing and routing traffic to microservices and handling cross‑cutting concerns.         | • Centralized API gateway vs. decentralized service mesh<br>• Authentication, routing, and load balancing at the gateway<br>• Observability and security for inter‑service calls         | • [What is an API Gateway? – NGINX](https://www.nginx.com/learn/api-gateway/)<br>• [What is a Service Mesh? – Istio](https://istio.io/latest/docs/concepts/what-is-istio/)                                                                         |
| Distributed Cache Pattern         | Patterns for caching data across multiple nodes to improve system performance and reduce latency.       | • Ensuring cache coherence<br>• Invalidation strategies and expiration policies<br>• Balancing data freshness with performance benefits                                              | • [Distributed Cache in Spring – Baeldung](https://www.baeldung.com/distributed-cache-in-spring)<br>• [Redis Caching – Redis Documentation](https://redis.io/topics/caching)       |


## Distributed Systems


Briefing Document: "Distributed Systems for Fun and Profit" - Chapter 2: Abstraction, Impossibility Results, and System Models
This briefing document summarizes the key themes and concepts presented in Chapter 2 of "Distributed Systems for Fun and Profit" by Mikito Takada. The chapter focuses on the importance of abstraction in managing the complexity of distributed systems, explores the implications of impossibility results like CAP and FLP, and introduces the concept of system models for defining the assumptions and constraints under which these systems operate.
Main Themes:
Abstraction is Essential but Inherently "Fake": Distributed programming is about dealing with the consequences of distribution, and abstraction is key to finding a balance between reality and a manageable system. Abstractions simplify by equating unequal things and ignoring non-essential aspects of a system. As the author states, "Abstractions, fundamentally, are fake. Every situation is unique, as is every node. But abstractions make the world manageable: simpler problem statements - free of reality - are much more analytically tractable." The trade-off lies in the risk of introducing errors or performance issues by excluding essential factors. "Every time we exclude some aspect of a system from our specification of the system, we risk introducing a source of error and/or a performance issue."
System Models Define Reality: A system model is a crucial specification of the characteristics considered important in a distributed system. It enumerates the many assumptions associated with a particular system design. Crucially, "A robust system model is one that makes the weakest assumptions: any algorithm written for such a system is very tolerant of different environments, since it makes very few and very weak assumptions." System models vary in their assumptions about the environment and facilities, including node capabilities and failure modes, communication link operation and failures, and assumptions about time and order.
Impossibility Results Highlight Fundamental Trade-offs: The chapter introduces two key impossibility results: the FLP impossibility result and the CAP theorem. These results highlight the inherent limitations and trade-offs in designing distributed systems, especially in the face of asynchrony and network partitions. Impossibility results take the simplest formulation of a problem, and demonstrate that it is impossible to solve within some set of constraints or assumptions.
CAP Theorem's Implications for Consistency and Availability: The CAP theorem states that a distributed system can only satisfy two out of the following three properties: Consistency, Availability, and Partition Tolerance. This forces a design choice during network partitions between maintaining consistency or maximizing availability. "Assuming that a partition occurs, the theorem reduces to a binary choice between availability and consistency." The author argues against a rigid "2 out of 3" interpretation, advocating for exploring alternative consistency models beyond strong consistency.
"Consistency" is Not Singular: The chapter emphasizes that "consistency" is not a fixed property but a contract between the programmer and the system. There are many consistency models, from strong consistency (Linearizable and Sequential) to weak consistency (Client-centric, Causal, and Eventual). "Consistency model a contract between programmer and system, wherein the system guarantees that if the programmer follows some specific rules, the results of operations on the data store will be predictable". The strong consistency models are able to maintain a single copy, while the weak consistency models cannot make such guarantees.
Key Concepts and Ideas:
Levels of Abstraction: Working at different layers, interfacing with lower-level APIs, and providing higher-level interfaces.
Consequences of Distribution: The challenges arising from the inherent distribution of nodes, networks, and lack of shared memory or clock.
System Model Components: Properties of nodes (computation, storage, clock), communication links (reliability, message order, partitions), and time/ordering assumptions (synchronous vs. asynchronous).
Node Failure Models: Crash-recovery vs. Byzantine fault tolerance.
Network Partitions: Situations where the network fails while nodes remain operational, leading to message loss and potential divergence.
Synchronous vs. Asynchronous Systems: Differing assumptions about timing, message delays, and clock accuracy. Asynchronicity assumes that you cannot rely on timing, or a "time sensor."
The Consensus Problem: The fundamental challenge of ensuring agreement among multiple nodes on a single value, requiring agreement, integrity, termination, and validity.
FLP Impossibility Result: No deterministic algorithm can solve consensus in an asynchronous system with even one faulty process.
CAP Theorem (Consistency, Availability, Partition Tolerance): A system can only guarantee two of these three properties simultaneously.
CA, CP, and AP Systems: Different system types based on which two properties of the CAP theorem are prioritized.
Strong vs. Weak Consistency Models: Different guarantees about data visibility and ordering, with trade-offs in performance and availability.
Linearizable vs. Sequential Consistency: Different requirements of operations, where Linearizable requires that the order in which operations take effect is equal to the actual real-time ordering of operations.
Key Quotes:
"Distributed programming is, I'd assert, in large part dealing with consequences of distribution (duh!). That is, there is a tension between the reality that there are many nodes and with our desire for systems that "work like a single system"."
"Every concept originates through our equating what is unequal. No leaf ever wholly equals another, and the concept "leaf" is formed through an arbitrary abstraction from these individual differences, through forgetting the distinctions; and now it gives rise to the idea that in nature there might be something besides the leaves which would be "leaf" - some kind of original form after which all leaves have been woven, marked, copied, colored, curled, and painted, but by unskilled hands, so that no copy turned out to be a correct, reliable, and faithful image of the original form."
"A system model enumerates the many assumptions associated with a particular system design."
"Assuming that a partition occurs, the theorem reduces to a binary choice between availability and consistency."
"Consistency model a contract between programmer and system, wherein the system guarantees that if the programmer follows some specific rules, the results of operations on the data store will be predictable."
Implications and Takeaways:
Understanding abstraction and its limitations is critical for designing effective distributed systems.
System models provide a structured way to define the assumptions and constraints under which a system operates.
Impossibility results like CAP and FLP force informed trade-offs between consistency, availability, and partition tolerance.
Strong consistency is not the only option; alternative consistency models can provide better performance or availability in certain scenarios.
This chapter lays the groundwork for understanding the fundamental challenges and design choices involved in building distributed systems, emphasizing the importance of considering trade-offs and choosing appropriate system models and consistency guarantees.
